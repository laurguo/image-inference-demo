<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ONNX Image Inference Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            min-height: 100vh;
            background: #f7f7f7;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            width: 100vw;
        }
        h1 {
            font-size: 2.5rem;
            margin-bottom: 32px;
            text-align: center;
        }
        #image-input {
            margin: 24px 0 16px 0;
            font-size: 1.2rem;
            padding: 10px 20px;
            border-radius: 8px;
            border: 1px solid #ccc;
            background: #fff;
            cursor: pointer;
            display: block;
        }
        #image-preview {
            max-width: 480px;
            max-height: 480px;
            margin-top: 10px;
            border-radius: 12px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
            display: none;
        }
        #result {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        canvas {
            max-width: 480px;
            max-height: 480px;
            border-radius: 12px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        }
        .label-text {
            font-size: 1.3rem;
            font-weight: bold;
            background: rgba(255,255,255,0.7);
            padding: 2px 8px;
            border-radius: 6px;
            margin-bottom: 8px;
        }
        @media (max-width: 600px) {
            h1 { font-size: 1.5rem; }
            #image-preview, canvas { max-width: 98vw; max-height: 60vw; }
        }
        .image-row {
            display: flex;
            flex-direction: row;
            align-items: flex-start;
            justify-content: center;
            gap: 40px;
            margin-top: 32px;
        }
        .image-col {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
        }
        .image-visual-wrapper {
            align-self: flex-start;
            display: flex;
            flex-direction: column;
        }
        .image-visual-wrapper.has-result {
            margin-top: 10px;
        }
        .image-col > img,
        .image-col > canvas {
            display: block;
            margin-bottom: 0;
            vertical-align: top;
        }
        .image-label {
            font-size: 1.1rem;
            margin-bottom: 8px;
            color: #333;
        }
        #image-preview, canvas {
            max-width: 480px;
            max-height: 480px;
            border-radius: 12px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
            margin-bottom: 0;
            vertical-align: top;
        }
        #result canvas {
            display: block;
        }
        @media (max-width: 1100px) {
            .image-row { flex-direction: column; gap: 16px; }
        }
        .centered-status {
            text-align: center;
            font-size: 1.2rem;
            color: #2a2a2a;
            margin-bottom: 12px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ONNX Image Inference Demo</h1>
        <h2 style="font-size:1.1rem; font-weight:normal; color:#444; margin-top:-18px; margin-bottom:18px; text-align:center; max-width:600px;">Model is trained on <a href='https://cocodataset.org/#home' target='_blank' style='color:#1976d2;text-decoration:underline;'>COCO</a> images (80 common object classes). For best results, try photos with people, cars, animals, household items, etc.</h2>
        <div id="model-status" class="centered-status"></div>
        <input type="file" id="image-input" accept="image/*" disabled>
        <div class="image-row">
            <div class="image-col">
                <span class="image-label">Input Image</span>
                <div class="image-visual-wrapper">
                    <img id="image-preview" src="" alt="Image preview"/>
                </div>
            </div>
            <div class="image-col">
                <span class="image-label">Inference Result</span>
                <div class="image-visual-wrapper">
                    <div id="result"></div>
                </div>
                <div id="class-key" style="margin-top:18px; display:flex; flex-direction:row; gap:18px; justify-content:center; align-items:center;"></div>
            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        const modelUrl = 'yolo11n-seg.onnx';
        let session;
        let inputShape = [1, 3, 640, 640];
        // COCO 80 class names
        const classNames = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',
            'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
            'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
            'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];
        // Generate 80 visually distinct colors for masks
        const maskColors = Array.from({length: 80}, (_, i) => {
            const hue = Math.floor((i * 360) / 80);
            const rgb = hsvToRgb(hue / 360, 0.7, 1.0);
            return rgb;
        });
        // HSV to RGB helper
        function hsvToRgb(h, s, v) {
            let r, g, b;
            let i = Math.floor(h * 6);
            let f = h * 6 - i;
            let p = v * (1 - s);
            let q = v * (1 - f * s);
            let t = v * (1 - (1 - f) * s);
            switch (i % 6) {
                case 0: r = v, g = t, b = p; break;
                case 1: r = q, g = v, b = p; break;
                case 2: r = p, g = v, b = t; break;
                case 3: r = p, g = q, b = v; break;
                case 4: r = t, g = p, b = v; break;
                case 5: r = v, g = p, b = q; break;
            }
            return [Math.round(r * 255), Math.round(g * 255), Math.round(b * 255)];
        }
        const maskAlpha = 0.5; // Moderate alpha for blending

        async function loadModel() {
            session = await ort.InferenceSession.create(modelUrl, { executionProviders: ['wasm'] });
            document.getElementById('model-status').innerText = 'Model loaded!';
            document.getElementById('image-input').disabled = false;
        }

        function letterboxImage(img, newShape = [640, 640], color = [114, 114, 114]) {
            // Returns: {canvas, ratio, dw, dh, newW, newH}
            const shape = [img.naturalHeight, img.naturalWidth];
            const r = Math.min(newShape[0] / shape[0], newShape[1] / shape[1]);
            const newUnpad = [Math.round(shape[1] * r), Math.round(shape[0] * r)];
            let dw = newShape[1] - newUnpad[0];
            let dh = newShape[0] - newUnpad[1];
            dw /= 2;
            dh /= 2;
            // Resize
            const resizedCanvas = document.createElement('canvas');
            resizedCanvas.width = newUnpad[0];
            resizedCanvas.height = newUnpad[1];
            const resizedCtx = resizedCanvas.getContext('2d');
            resizedCtx.drawImage(img, 0, 0, newUnpad[0], newUnpad[1]);
            // Letterbox
            const canvas = document.createElement('canvas');
            canvas.width = newShape[1];
            canvas.height = newShape[0];
            const ctx = canvas.getContext('2d');
            ctx.fillStyle = `rgb(${color[0]},${color[1]},${color[2]})`;
            ctx.fillRect(0, 0, newShape[1], newShape[0]);
            ctx.drawImage(resizedCanvas, Math.round(dw - 0.1), Math.round(dh - 0.1));
            return {canvas, ratio: r, dw, dh, newW: newUnpad[0], newH: newUnpad[1]};
        }

        function preprocessImage(img) {
            // Letterbox and normalize
            const {canvas, ratio, dw, dh, newW, newH} = letterboxImage(img);
            const ctx = canvas.getContext('2d');
            const imageData = ctx.getImageData(0, 0, 640, 640);
            const { data } = imageData;
            const floatData = new Float32Array(3 * 640 * 640);
            let idx = 0;
            for (let c = 0; c < 3; c++) {
                for (let y = 0; y < 640; y++) {
                    for (let x = 0; x < 640; x++) {
                        const i = (y * 640 + x) * 4;
                        floatData[idx++] = data[i + c] / 255.0;
                    }
                }
            }
            return {floatData, ratio, dw, dh};
        }

        function sigmoid(x) {
            return 1 / (1 + Math.exp(-x));
        }

        function softmax(arr) {
            const max = Math.max(...arr);
            const exps = arr.map(x => Math.exp(x - max));
            const sum = exps.reduce((a, b) => a + b);
            return exps.map(x => x / sum);
        }

        function boxIoU(boxA, boxB) {
            const xA = Math.max(boxA[0], boxB[0]);
            const yA = Math.max(boxA[1], boxB[1]);
            const xB = Math.min(boxA[2], boxB[2]);
            const yB = Math.min(boxA[3], boxB[3]);
            const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
            const boxAArea = Math.max(0, boxA[2] - boxA[0]) * Math.max(0, boxA[3] - boxA[1]);
            const boxBArea = Math.max(0, boxB[2] - boxB[0]) * Math.max(0, boxB[3] - boxB[1]);
            return interArea / (boxAArea + boxBArea - interArea + 1e-6);
        }

        function postprocessYOLOSeg(output0, output1, img, origW, origH, ratio, dw, dh) {
            const numClasses = classNames.length;
            const nChannels = 32;
            const nBboxes = 8400;
            const maskH = 160, maskW = 160;
            const stride = 640 / maskW;
            const confThreshold = 0.02;
            const maskThreshold = 0.7;
            const maxDetections = 100; // You can increase if your browser is fast
            const boxesArr = output0.data;
            const maskProtos = output1.data;
            let maskProtosArr = [];
            for (let c = 0; c < nChannels; c++) {
                let channel = [];
                for (let y = 0; y < maskH; y++) {
                    for (let x = 0; x < maskW; x++) {
                        channel.push(maskProtos[c * maskH * maskW + y * maskW + x]);
                    }
                }
                maskProtosArr.push(channel);
            }
            // Parse detections
            let detections = [];
            for (let i = 0; i < nBboxes; i++) {
                const classScores = [];
                for (let c = 0; c < numClasses; c++) {
                    classScores.push(boxesArr[(4 + c) * nBboxes + i]);
                }
                const classProbs = softmax(classScores);
                const classId = classProbs.indexOf(Math.max(...classProbs));
                const score = classProbs[classId];
                if (score < confThreshold) continue;
                const maskCoeffs = [];
                for (let c = 0; c < nChannels; c++) {
                    maskCoeffs.push(boxesArr[(4 + numClasses + c) * nBboxes + i]);
                }
                detections.push({classId, score, maskCoeffs});
            }
            // Sort by confidence and keep top N
            detections.sort((a, b) => b.score - a.score);
            const topDetections = detections.slice(0, maxDetections);
            // Prepare mask canvas
            const maskCanvas = document.createElement('canvas');
            maskCanvas.width = origW;
            maskCanvas.height = origH;
            const maskCtx = maskCanvas.getContext('2d');
            maskCtx.drawImage(img, 0, 0, origW, origH);
            // For each pixel, keep the highest mask value and its class among topDetections (true per-pixel max, like Python)
            const pixelScores = new Float32Array(origW * origH).fill(0);
            const pixelClasses = new Int8Array(origW * origH).fill(-1);
            topDetections.forEach(det => {
                // Compose mask
                let mask = new Float32Array(maskH * maskW);
                for (let i = 0; i < mask.length; i++) {
                    let val = 0;
                    for (let c = 0; c < nChannels; c++) {
                        val += maskProtosArr[c][i] * det.maskCoeffs[c];
                    }
                    mask[i] = sigmoid(val);
                }
                // Resize mask to 640x640
                const mask2d = new Float32Array(640 * 640);
                for (let y = 0; y < 640; y++) {
                    for (let x = 0; x < 640; x++) {
                        const srcX = x / 4;
                        const srcY = y / 4;
                        const x0 = Math.floor(srcX), x1 = Math.min(Math.ceil(srcX), 159);
                        const y0 = Math.floor(srcY), y1 = Math.min(Math.ceil(srcY), 159);
                        const dx = srcX - x0, dy = srcY - y0;
                        const v00 = mask[y0 * 160 + x0];
                        const v01 = mask[y0 * 160 + x1];
                        const v10 = mask[y1 * 160 + x0];
                        const v11 = mask[y1 * 160 + x1];
                        const v0 = v00 * (1 - dx) + v01 * dx;
                        const v1 = v10 * (1 - dx) + v11 * dx;
                        mask2d[y * 640 + x] = v0 * (1 - dy) + v1 * dy;
                    }
                }
                // Remove letterbox padding and resize to original image size
                const left = Math.round(dw - 0.1);
                const right = 640 - Math.round(dw + 0.1);
                const top = Math.round(dh - 0.1);
                const bottom = 640 - Math.round(dh + 0.1);
                const cropW = right - left;
                const cropH = bottom - top;
                for (let y = 0; y < origH; y++) {
                    for (let x = 0; x < origW; x++) {
                        const cx = x / origW * cropW;
                        const cy = y / origH * cropH;
                        const ix = Math.min(Math.floor(cx), cropW - 1);
                        const iy = Math.min(Math.floor(cy), cropH - 1);
                        const v = mask2d[(top + iy) * 640 + (left + ix)];
                        const idx = y * origW + x;
                        if (v > pixelScores[idx]) {
                            pixelScores[idx] = v;
                            pixelClasses[idx] = det.classId;
                        }
                    }
                }
            });
            // Track detected class indices and their mask area
            const classAreaMap = new Map(); // classIdx -> pixel count
            for (let i = 0; i < origW * origH; i++) {
                const classIdx = pixelClasses[i];
                if (classIdx >= 0 && pixelScores[i] > maskThreshold) {
                    classAreaMap.set(classIdx, (classAreaMap.get(classIdx) || 0) + 1);
                }
            }
            // Remove classes with mask area less than 1% of the image
            const minArea = 0.03 * origW * origH;
            for (const [classIdx, area] of classAreaMap.entries()) {
                if (area < minArea) {
                    classAreaMap.delete(classIdx);
                }
            }
            // Get top 5 classes by area
            const detectedClassIndices = Array.from(classAreaMap.entries())
                .sort((a, b) => b[1] - a[1])
                .slice(0, 5)
                .map(([classIdx, _]) => classIdx);
            // Assign a color for each detected class (HSV evenly spaced)
            const classColorMap = {};
            detectedClassIndices.forEach((classIdx, i) => {
                classColorMap[classIdx] = hsvToRgb(i / detectedClassIndices.length, 0.7, 1.0);
            });
            // Overlay the final mask (only where mask > threshold)
            const maskImageData = maskCtx.getImageData(0, 0, origW, origH);
            for (let i = 0; i < origW * origH; i++) {
                const classIdx = pixelClasses[i];
                if (classIdx >= 0 && pixelScores[i] > maskThreshold && classColorMap[classIdx]) {
                    const color = classColorMap[classIdx];
                    maskImageData.data[i * 4 + 0] = color[0] * maskAlpha + maskImageData.data[i * 4 + 0] * (1 - maskAlpha);
                    maskImageData.data[i * 4 + 1] = color[1] * maskAlpha + maskImageData.data[i * 4 + 1] * (1 - maskAlpha);
                    maskImageData.data[i * 4 + 2] = color[2] * maskAlpha + maskImageData.data[i * 4 + 2] * (1 - maskAlpha);
                }
            }
            maskCtx.putImageData(maskImageData, 0, 0);
            return {maskCanvas, detectedClassIndices, classColorMap};
        }

        async function runInference(img, origW, origH) {
            if (!session) {
                document.getElementById('model-status').innerText = 'Model not loaded yet!';
                return;
            }
            document.getElementById('model-status').innerText = '';
            document.getElementById('result').innerText = 'Running inference...';
            const {floatData, ratio, dw, dh} = preprocessImage(img);
            const tensor = new ort.Tensor('float32', floatData, inputShape);
            const feeds = {};
            feeds[session.inputNames[0]] = tensor;
            const outputMap = await session.run(feeds);
            const output0 = outputMap[session.outputNames[0]];
            const output1 = outputMap[session.outputNames[1]];
            // Get maskCanvas and detected class indices
            const {maskCanvas, detectedClassIndices, classColorMap} = postprocessYOLOSeg(output0, output1, img, origW, origH, ratio, dw, dh);
            const resultDiv = document.getElementById('result');
            const resultWrapper = resultDiv.parentElement;
            resultDiv.innerHTML = '';
            resultDiv.appendChild(maskCanvas);
            resultWrapper.classList.add('has-result');
            renderClassKey(detectedClassIndices, classColorMap);
        }

        document.getElementById('image-input').addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;
            const img = new window.Image();
            img.onload = async () => {
                document.getElementById('image-preview').src = img.src;
                document.getElementById('image-preview').style.display = 'block';
                document.getElementById('result').innerText = '';
                document.getElementById('result').parentElement.classList.remove('has-result');
                await runInference(img, img.naturalWidth, img.naturalHeight);
            };
            img.src = URL.createObjectURL(file);
        });

        loadModel();

        // After showing the result, render the class key
        function renderClassKey(detectedClassIndices, classColorMap) {
            const keyDiv = document.getElementById('class-key');
            keyDiv.innerHTML = '';
            if (!detectedClassIndices || detectedClassIndices.length === 0) {
                keyDiv.innerText = 'No objects detected.';
                return;
            }
            for (const i of detectedClassIndices) {
                const swatch = document.createElement('span');
                swatch.style.display = 'inline-block';
                swatch.style.width = '22px';
                swatch.style.height = '22px';
                const color = classColorMap && classColorMap[i] ? classColorMap[i] : [200,200,200];
                swatch.style.background = `rgb(${color[0]},${color[1]},${color[2]})`;
                swatch.style.border = '2px solid #222';
                swatch.style.marginRight = '7px';
                swatch.style.verticalAlign = 'middle';
                const label = document.createElement('span');
                label.style.fontSize = '1.1rem';
                label.style.verticalAlign = 'middle';
                label.innerText = classNames[i];
                const item = document.createElement('span');
                item.style.display = 'inline-flex';
                item.style.alignItems = 'center';
                item.appendChild(swatch);
                item.appendChild(label);
                keyDiv.appendChild(item);
            }
        }
    </script>
</body>
</html> 